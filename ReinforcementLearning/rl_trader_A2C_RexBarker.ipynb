{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "## A2C stock trader, based on rl_trader.py\n",
    "###########################################\n",
    "\n",
    "# Requires Spark configuration:\n",
    "#\n",
    "#  spark.rpc.message.maxSize 2000\n",
    "#  spark.databricks.workspace.matplotlibInline.enabled true\n",
    "#  spark.sql.execution.arrow.enabled true\n",
    "#  spark.databricks.delta.preview.enabled true\n",
    "#  spark.driver.maxResultSize 0\n",
    "#\n",
    "# Requires environment variables:\n",
    "#  ARROW_PRE_0_15_IPC_FORMAT=1http://localhost:8888/notebooks/20200310/rl_trader_A2C_RexBarker.ipynb#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/botocore/vendored/requests/packages/urllib3/_collections.py:1: DeprecationWarning: Using or importing the ABCs from &#39;collections&#39; instead of from &#39;collections.abc&#39; is deprecated, and in 3.8 it will stop working\n",
       "  from collections import Mapping, MutableMapping\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from glob import glob,iglob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import argparse\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "basedir = '/dbfs/dbfs/tradingA2C'\n",
    "datadir = '/dbfs/FileStore/tables'\n",
    "# create base directory if not existing\n",
    "if not os.path.exists(basedir): os.mkdir(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">/dbfs/FileStore/tables/ABBN_SW-00610.csv\n",
       "/dbfs/FileStore/tables/ADEN_SW-51ff6.csv\n",
       "/dbfs/FileStore/tables/BAER_SW-b24d5.csv\n",
       "/dbfs/FileStore/tables/CFR_SW-d4c0e.csv\n",
       "/dbfs/FileStore/tables/CSGN_SW-c23f4.csv\n",
       "/dbfs/FileStore/tables/GEBN_SW-2fa7b.csv\n",
       "/dbfs/FileStore/tables/GIVN_SW-6a07c.csv\n",
       "/dbfs/FileStore/tables/LHN_SW-c244f.csv\n",
       "/dbfs/FileStore/tables/LONN_SW-b2c9c.csv\n",
       "/dbfs/FileStore/tables/NESN_SW-8ed23.csv\n",
       "/dbfs/FileStore/tables/NOVN_SW-3c3e6.csv\n",
       "/dbfs/FileStore/tables/ROG_SW-18dc4.csv\n",
       "/dbfs/FileStore/tables/SCMN_SW-cb9a3.csv\n",
       "/dbfs/FileStore/tables/SGSN_SW-4a845.csv\n",
       "/dbfs/FileStore/tables/SIKA_SW-b2c47.csv\n",
       "/dbfs/FileStore/tables/SLHN_SW-40dcd.csv\n",
       "/dbfs/FileStore/tables/SREN_SW-603e7.csv\n",
       "/dbfs/FileStore/tables/UBSG_SW-232ee.csv\n",
       "/dbfs/FileStore/tables/UHR_SW-2b446.csv\n",
       "/dbfs/FileStore/tables/ZURN_SW-57931.csv\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for s in iglob(os.path.join(datadir,\"*_SW*.csv\")):\n",
    "  print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Currently configured for 3 stocks\n",
    "df_all = pd.DataFrame()\n",
    "stocks = ['ABBN','NESN', 'UBSG']\n",
    "for s in stocks:\n",
    "  files = glob(os.path.join(datadir,f\"{s}*.csv\"))\n",
    "  assert files, f\"Stock '{s}' file was not found!\"\n",
    "  filepath = files[0]\n",
    "  df = pd.read_csv(filepath)\n",
    "  df.index = df.Date\n",
    "  df_all[s] = df.Close\n",
    "\n",
    "df_all.interpolate(inplace=True,limit_direction='both')\n",
    "df_all.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[df_all.index > '2019-01-01'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entire range of data, StandardScaled\n",
    "scaler = StandardScaler().fit(df_all)\n",
    "df_scaled = scaler.transform(df_all)\n",
    "plt.plot(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduced set of data, for test/train\n",
    "df_use = df_all.loc[df_all.index > '2018-01-01']\n",
    "scaler.fit(df_use)\n",
    "plt.plot(scaler.transform(df_use))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_data():\n",
    "  # Let's use AAPL (Apple), MSI (Motorola), SBUX (Starbucks)\n",
    "  # returns a T x 3 list of stock prices\n",
    "  # each row is a different stock\n",
    "  # 0 = AAPL\n",
    "  # 1 = MSI\n",
    "  # 2 = SBUX\n",
    "  #csvfile = os.path.join(basedir,'aapl_msi_sbux.csv')\n",
    "  #assert os.path.exists(csvfile)\n",
    "  #df = pd.read_csv(csvfile)\n",
    "  return df_use.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def maybe_make_dir(directory):\n",
    "  if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_scaler(env):\n",
    "  # return scikit-learn scaler object to scale the states\n",
    "  # Note: you could also populate the replay buffer here\n",
    "\n",
    "  states = []\n",
    "  for _ in range(env.n_step):\n",
    "    action = np.random.choice(env.action_space)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    states.append(state)\n",
    "    if done:\n",
    "      break\n",
    "\n",
    "  scaler = StandardScaler()\n",
    "  scaler.fit(states)\n",
    "  return scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def play_one_episode(agent, env, is_train):\n",
    "  # note: after transforming states are already 1xD\n",
    "  state = env.reset()\n",
    "  state = scaler.transform([state])\n",
    "  done = False\n",
    "\n",
    "  while not done:\n",
    "    action = agent.act(state)\n",
    "    next_state, reward, done, info = env.step(action)\n",
    "    next_state = scaler.transform([next_state])\n",
    "    if is_train == 'train':\n",
    "      agent.update_replay_memory(state, action, reward, next_state, done)\n",
    "      agent.replay(batch_size)\n",
    "    state = next_state\n",
    "\n",
    "  return info['cur_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ReplayBuffer:\n",
    "  ### The experience replay memory ###\n",
    "  def __init__(self, obs_dim, act_dim, size):\n",
    "    self.obs1_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "    self.obs2_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "    self.acts_buf = np.zeros(size, dtype=np.uint8)\n",
    "    self.rews_buf = np.zeros(size, dtype=np.float32)\n",
    "    self.done_buf = np.zeros(size, dtype=np.uint8)\n",
    "    self.ptr, self.size, self.max_size = 0, 0, size\n",
    "\n",
    "  def store(self, obs, act, rew, next_obs, done):\n",
    "    self.obs1_buf[self.ptr] = obs\n",
    "    self.obs2_buf[self.ptr] = next_obs\n",
    "    self.acts_buf[self.ptr] = act\n",
    "    self.rews_buf[self.ptr] = rew\n",
    "    self.done_buf[self.ptr] = done\n",
    "    self.ptr = (self.ptr+1) % self.max_size\n",
    "    self.size = min(self.size+1, self.max_size)\n",
    "\n",
    "  def sample_batch(self, batch_size=32):\n",
    "    idxs = np.random.randint(0, self.size, size=batch_size)\n",
    "    return dict(s=self.obs1_buf[idxs],\n",
    "                s2=self.obs2_buf[idxs],\n",
    "                a=self.acts_buf[idxs],\n",
    "                r=self.rews_buf[idxs],\n",
    "                d=self.done_buf[idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mlp_actor(input_dim, n_action, n_hidden_layers=1, hidden_dim=32):\n",
    "  \"\"\" A multi-layer perceptron \"\"\"\n",
    "\n",
    "  # input layer\n",
    "  i = Input(shape=(input_dim,))\n",
    "  x = i\n",
    "\n",
    "  # hidden layers\n",
    "  for _ in range(n_hidden_layers):\n",
    "    x = Dense(hidden_dim, activation='relu')(x)\n",
    "  \n",
    "  # final layer\n",
    "  x = Dense(n_action, activation = 'softmax')(x)\n",
    "\n",
    "  # make the model\n",
    "  model = Model(i, x)\n",
    "\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "  print((model.summary()))\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mlp_critic(input_dim, n_action, n_hidden_layers=1, hidden_dim=32):\n",
    "  \"\"\" A multi-layer perceptron \"\"\"\n",
    "\n",
    "  # input layer\n",
    "  i = Input(shape=(input_dim,))\n",
    "  x = i\n",
    "\n",
    "  # hidden layers\n",
    "  for _ in range(n_hidden_layers):\n",
    "    x = Dense(hidden_dim, activation='relu')(x)\n",
    "  \n",
    "  # final layer\n",
    "  x = Dense(n_action, activation = 'linear')(x)\n",
    "\n",
    "  # make the model\n",
    "  model = Model(i, x)\n",
    "\n",
    "  model.compile(loss='mse', optimizer='adam')\n",
    "  print((model.summary()))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class DQNAgent(object):\n",
    "  def __init__(self, state_size, action_size):\n",
    "    self.state_size = state_size\n",
    "    self.action_size = action_size\n",
    "    self.memory = ReplayBuffer(state_size, action_size, size=500)\n",
    "    self.gamma = 0.95  # discount rate\n",
    "    self.epsilon = 1.0  # exploration rate\n",
    "    self.epsilon_min = 0.01\n",
    "    self.epsilon_decay = 0.995\n",
    "    self.critic_model = mlp_critic(state_size, action_size)\n",
    "    self.actor_model = mlp_actor(state_size, action_size)\n",
    "\n",
    "\n",
    "  def update_replay_memory(self, state, action, reward, next_state, done):\n",
    "    self.memory.store(state, action, reward, next_state, done)\n",
    "\n",
    "\n",
    "  def act(self, state):\n",
    "    if np.random.rand() <= self.epsilon:\n",
    "      return np.random.choice(self.action_size)\n",
    "    values = self.critic_model.predict(state)\n",
    "    return np.argmax(values[0])  # returns action\n",
    "\n",
    "\n",
    "  def replay(self, batch_size=32):\n",
    "    # first check if replay buffer contains enough data\n",
    "    if self.memory.size < batch_size:\n",
    "      return\n",
    "\n",
    "    # sample a batch of data from the replay memory\n",
    "    minibatch = self.memory.sample_batch(batch_size)\n",
    "    states = minibatch['s']\n",
    "    actions = minibatch['a']\n",
    "    rewards = minibatch['r']\n",
    "    next_states = minibatch['s2']\n",
    "    done = minibatch['d']\n",
    "    advantages = np.zeros((batch_size, self.action_size))\n",
    "    \n",
    "    values = self.critic_model.predict(states)\n",
    "    next_values = self.critic_model.predict(next_states)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "      action = actions[i]\n",
    "      if done[i]:\n",
    "        advantages[i][action] = rewards[i] - values[i][action]\n",
    "        values[i][action] = rewards[i]\n",
    "      else:\n",
    "        advantages[i][action] = (rewards[i] - self.gamma * next_values[i][action]) - values[i][action]\n",
    "        values[i][action] = rewards[i] + self.gamma * next_values[i][action]\n",
    "\n",
    "\n",
    "    # Calculate the tentative target: Q(s',a)\n",
    "    ##target = rewards + self.gamma * np.amax(self.model.predict(next_states), axis=1)\n",
    "\n",
    "    # The value of terminal states is zero\n",
    "    # so set the target to be the reward only\n",
    "    ##target[done] = rewards[done]\n",
    "\n",
    "    # With the Keras API, the target (usually) must have the same\n",
    "    # shape as the predictions.\n",
    "    # However, we only need to update the network for the actions\n",
    "    # which were actually taken.\n",
    "    # We can accomplish this by setting the target to be equal to\n",
    "    # the prediction for all values.\n",
    "    # Then, only change the targets for the actions taken.\n",
    "    # Q(s,a)\n",
    "    ##target_full = self.model.predict(states)\n",
    "    ##target_full[np.arange(batch_size), actions] = target\n",
    "\n",
    "    # Run one training step\n",
    "    self.actor_model.train_on_batch(states, advantages)\n",
    "    self.critic_model.train_on_batch(states, values)\n",
    "\n",
    "    if self.epsilon > self.epsilon_min:\n",
    "      self.epsilon *= self.epsilon_decay\n",
    "\n",
    "\n",
    "  def load(self, name):\n",
    "    dirname = os.path.dirname(name)\n",
    "    filename = os.path.basename(name)\n",
    "    \n",
    "    self.actor_model.load_weights(os.path.join(dirname,'actor_' + filename))\n",
    "    self.critic_model.load_weights(os.path.join(dirname,'critic_' + filename))\n",
    "\n",
    "\n",
    "  def save(self, name):\n",
    "    dirname = os.path.dirname(name)\n",
    "    filename = os.path.basename(name)\n",
    "    \n",
    "    self.actor_model.save_weights(os.path.join(dirname,'actor_' + filename))\n",
    "    self.critic_model.save_weights(os.path.join(dirname,'critic_' + filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MultiStockEnv:\n",
    "  \"\"\"\n",
    "  A 3-stock trading environment.\n",
    "  State: vector of size 7 (n_stock * 2 + 1)\n",
    "    - # shares of stock 1 owned\n",
    "    - # shares of stock 2 owned\n",
    "    - # shares of stock 3 owned\n",
    "    - price of stock 1 (using daily close price)\n",
    "    - price of stock 2\n",
    "    - price of stock 3\n",
    "    - cash owned (can be used to purchase more stocks)\n",
    "  Action: categorical variable with 27 (3^3) possibilities\n",
    "    - for each stock, you can:\n",
    "    - 0 = sell\n",
    "    - 1 = hold\n",
    "    - 2 = buy\n",
    "  \"\"\"\n",
    "  def __init__(self, data, initial_investment=20000):\n",
    "    # data\n",
    "    self.stock_price_history = data\n",
    "    self.n_step, self.n_stock = self.stock_price_history.shape\n",
    "\n",
    "    # instance attributes\n",
    "    self.initial_investment = initial_investment\n",
    "    self.cur_step = None\n",
    "    self.stock_owned = None\n",
    "    self.stock_price = None\n",
    "    self.cash_in_hand = None\n",
    "\n",
    "    self.action_space = np.arange(3**self.n_stock)\n",
    "\n",
    "    # action permutations\n",
    "    # returns a nested list with elements like:\n",
    "    # [0,0,0]\n",
    "    # [0,0,1]\n",
    "    # [0,0,2]\n",
    "    # [0,1,0]\n",
    "    # [0,1,1]\n",
    "    # etc.\n",
    "    # 0 = sell\n",
    "    # 1 = hold\n",
    "    # 2 = buy\n",
    "    self.action_list = list(map(list, itertools.product([0, 1, 2], repeat=self.n_stock)))\n",
    "\n",
    "    # calculate size of state\n",
    "    self.state_dim = self.n_stock * 2 + 1\n",
    "\n",
    "    self.reset()\n",
    "\n",
    "\n",
    "  def reset(self):\n",
    "    self.cur_step = 0\n",
    "    self.stock_owned = np.zeros(self.n_stock)\n",
    "    self.stock_price = self.stock_price_history[self.cur_step]\n",
    "    self.cash_in_hand = self.initial_investment\n",
    "    return self._get_obs()\n",
    "\n",
    "\n",
    "  def step(self, action):\n",
    "    assert action in self.action_space\n",
    "\n",
    "    # get current value before performing the action\n",
    "    prev_val = self._get_val()\n",
    "\n",
    "    # update price, i.e. go to the next day\n",
    "    self.cur_step += 1\n",
    "    self.stock_price = self.stock_price_history[self.cur_step]\n",
    "\n",
    "    # perform the trade\n",
    "    self._trade(action)\n",
    "\n",
    "    # get the new value after taking the action\n",
    "    cur_val = self._get_val()\n",
    "\n",
    "    # reward is the increase in porfolio value\n",
    "    reward = cur_val - prev_val\n",
    "\n",
    "    # done if we have run out of data\n",
    "    done = self.cur_step == self.n_step - 1\n",
    "\n",
    "    # store the current value of the portfolio here\n",
    "    info = {'cur_val': cur_val}\n",
    "\n",
    "    # conform to the Gym API\n",
    "    return self._get_obs(), reward, done, info\n",
    "\n",
    "\n",
    "  def _get_obs(self):\n",
    "    obs = np.empty(self.state_dim)\n",
    "    obs[:self.n_stock] = self.stock_owned\n",
    "    obs[self.n_stock:2*self.n_stock] = self.stock_price\n",
    "    obs[-1] = self.cash_in_hand\n",
    "    return obs\n",
    "    \n",
    "\n",
    "\n",
    "  def _get_val(self):\n",
    "    return self.stock_owned.dot(self.stock_price) + self.cash_in_hand\n",
    "\n",
    "\n",
    "  def _trade(self, action):\n",
    "    # index the action we want to perform\n",
    "    # 0 = sell\n",
    "    # 1 = hold\n",
    "    # 2 = buy\n",
    "    # e.g. [2,1,0] means:\n",
    "    # buy first stock\n",
    "    # hold second stock\n",
    "    # sell third stock\n",
    "    action_vec = self.action_list[action]\n",
    "\n",
    "    # determine which stocks to buy or sell\n",
    "    sell_index = [] # stores index of stocks we want to sell\n",
    "    buy_index = [] # stores index of stocks we want to buy\n",
    "    for i, a in enumerate(action_vec):\n",
    "      if a == 0:\n",
    "        sell_index.append(i)\n",
    "      elif a == 2:\n",
    "        buy_index.append(i)\n",
    "\n",
    "    # sell any stocks we want to sell\n",
    "    # then buy any stocks we want to buy\n",
    "    if sell_index:\n",
    "      # NOTE: to simplify the problem, when we sell, we will sell ALL shares of that stock\n",
    "      for i in sell_index:\n",
    "        self.cash_in_hand += self.stock_price[i] * self.stock_owned[i]\n",
    "        self.stock_owned[i] = 0\n",
    "    if buy_index:\n",
    "      # NOTE: when buying, we will loop through each stock we want to buy,\n",
    "      #       and buy one share at a time until we run out of cash\n",
    "      can_buy = True\n",
    "      while can_buy:\n",
    "        for i in buy_index:\n",
    "          if self.cash_in_hand > self.stock_price[i]:\n",
    "            self.stock_owned[i] += 1 # buy one share\n",
    "            self.cash_in_hand -= self.stock_price[i]\n",
    "          else:\n",
    "            can_buy = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# config\n",
    "models_folder = os.path.join(basedir,'rl_trader_models')\n",
    "rewards_folder = os.path.join(basedir,'rl_trader_rewards')\n",
    "num_episodes = 200\n",
    "batch_size = 32\n",
    "initial_investment = 20000\n",
    "\n",
    "mode = 'train'\n",
    "\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument('-m', '--mode', type=str, required=True,\n",
    "#                    help='either \"train\" or \"test\"')\n",
    "#args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Model: &#34;model_6&#34;\n",
       "_________________________________________________________________\n",
       "Layer (type)                 Output Shape              Param #   \n",
       "=================================================================\n",
       "input_7 (InputLayer)         [(None, 7)]               0         \n",
       "_________________________________________________________________\n",
       "dense_12 (Dense)             (None, 32)                256       \n",
       "_________________________________________________________________\n",
       "dense_13 (Dense)             (None, 27)                891       \n",
       "=================================================================\n",
       "Total params: 1,147\n",
       "Trainable params: 1,147\n",
       "Non-trainable params: 0\n",
       "_________________________________________________________________\n",
       "None\n",
       "Model: &#34;model_7&#34;\n",
       "_________________________________________________________________\n",
       "Layer (type)                 Output Shape              Param #   \n",
       "=================================================================\n",
       "input_8 (InputLayer)         [(None, 7)]               0         \n",
       "_________________________________________________________________\n",
       "dense_14 (Dense)             (None, 32)                256       \n",
       "_________________________________________________________________\n",
       "dense_15 (Dense)             (None, 27)                891       \n",
       "=================================================================\n",
       "Total params: 1,147\n",
       "Trainable params: 1,147\n",
       "Non-trainable params: 0\n",
       "_________________________________________________________________\n",
       "None\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maybe_make_dir(models_folder)\n",
    "maybe_make_dir(rewards_folder)\n",
    "\n",
    "data = get_data()\n",
    "n_timesteps, n_stocks = data.shape\n",
    "\n",
    "n_train = n_timesteps // 2\n",
    "\n",
    "train_data = data[:n_train]\n",
    "test_data = data[n_train:]\n",
    "\n",
    "env = MultiStockEnv(train_data, initial_investment)\n",
    "state_size = env.state_dim\n",
    "action_size = len(env.action_space)\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "scaler = get_scaler(env)\n",
    "\n",
    "# store the final value of the portfolio (end of episode)\n",
    "portfolio_value = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">episode: 1/200, episode end value: 12582.12, duration: 0:00:02.678560\n",
       "episode: 2/200, episode end value: 16585.00, duration: 0:00:02.088884\n",
       "episode: 3/200, episode end value: 14927.33, duration: 0:00:02.010060\n",
       "episode: 4/200, episode end value: 17188.36, duration: 0:00:02.004237\n",
       "episode: 5/200, episode end value: 20308.43, duration: 0:00:02.003888\n",
       "episode: 6/200, episode end value: 20143.91, duration: 0:00:01.989208\n",
       "episode: 7/200, episode end value: 17647.46, duration: 0:00:02.052717\n",
       "episode: 8/200, episode end value: 18872.93, duration: 0:00:02.035868\n",
       "episode: 9/200, episode end value: 18432.00, duration: 0:00:02.049522\n",
       "episode: 10/200, episode end value: 19635.29, duration: 0:00:02.004519\n",
       "episode: 11/200, episode end value: 20287.05, duration: 0:00:02.032396\n",
       "episode: 12/200, episode end value: 17564.06, duration: 0:00:02.002735\n",
       "episode: 13/200, episode end value: 19924.80, duration: 0:00:02.084612\n",
       "episode: 14/200, episode end value: 16632.92, duration: 0:00:02.045095\n",
       "episode: 15/200, episode end value: 17332.27, duration: 0:00:02.017168\n",
       "episode: 16/200, episode end value: 21841.29, duration: 0:00:01.996672\n",
       "episode: 17/200, episode end value: 19141.79, duration: 0:00:02.029160\n",
       "episode: 18/200, episode end value: 17156.49, duration: 0:00:02.153552\n",
       "episode: 19/200, episode end value: 20777.71, duration: 0:00:02.004764\n",
       "episode: 20/200, episode end value: 16284.17, duration: 0:00:02.021841\n",
       "episode: 21/200, episode end value: 17863.06, duration: 0:00:01.992297\n",
       "episode: 22/200, episode end value: 14878.17, duration: 0:00:02.032309\n",
       "episode: 23/200, episode end value: 21485.33, duration: 0:00:02.020921\n",
       "episode: 24/200, episode end value: 20886.59, duration: 0:00:02.008187\n",
       "episode: 25/200, episode end value: 21351.98, duration: 0:00:02.044627\n",
       "episode: 26/200, episode end value: 20520.54, duration: 0:00:02.066470\n",
       "episode: 27/200, episode end value: 19392.92, duration: 0:00:02.052730\n",
       "episode: 28/200, episode end value: 22023.30, duration: 0:00:02.036862\n",
       "episode: 29/200, episode end value: 19727.99, duration: 0:00:02.029181\n",
       "episode: 30/200, episode end value: 19770.89, duration: 0:00:02.083227\n",
       "episode: 31/200, episode end value: 20317.24, duration: 0:00:02.043131\n",
       "episode: 32/200, episode end value: 22367.48, duration: 0:00:02.014599\n",
       "episode: 33/200, episode end value: 20979.68, duration: 0:00:02.045122\n",
       "episode: 34/200, episode end value: 18603.71, duration: 0:00:02.127584\n",
       "episode: 35/200, episode end value: 21385.29, duration: 0:00:02.017659\n",
       "episode: 36/200, episode end value: 20929.26, duration: 0:00:02.049957\n",
       "episode: 37/200, episode end value: 19651.62, duration: 0:00:02.031782\n",
       "episode: 38/200, episode end value: 20300.20, duration: 0:00:02.009654\n",
       "episode: 39/200, episode end value: 19605.47, duration: 0:00:02.005561\n",
       "episode: 40/200, episode end value: 20598.92, duration: 0:00:02.061946\n",
       "episode: 41/200, episode end value: 19059.07, duration: 0:00:02.025007\n",
       "episode: 42/200, episode end value: 21027.11, duration: 0:00:02.059786\n",
       "episode: 43/200, episode end value: 20977.15, duration: 0:00:02.015339\n",
       "episode: 44/200, episode end value: 19500.87, duration: 0:00:02.049091\n",
       "episode: 45/200, episode end value: 20872.15, duration: 0:00:02.049981\n",
       "episode: 46/200, episode end value: 19855.67, duration: 0:00:02.069638\n",
       "episode: 47/200, episode end value: 20125.06, duration: 0:00:02.423850\n",
       "episode: 48/200, episode end value: 19803.86, duration: 0:00:02.039603\n",
       "episode: 49/200, episode end value: 21077.93, duration: 0:00:02.229233\n",
       "episode: 50/200, episode end value: 20776.84, duration: 0:00:02.001620\n",
       "episode: 51/200, episode end value: 22431.09, duration: 0:00:02.063539\n",
       "episode: 52/200, episode end value: 19645.98, duration: 0:00:02.095423\n",
       "episode: 53/200, episode end value: 22141.67, duration: 0:00:02.018081\n",
       "episode: 54/200, episode end value: 16885.22, duration: 0:00:02.008501\n",
       "episode: 55/200, episode end value: 20720.88, duration: 0:00:02.016616\n",
       "episode: 56/200, episode end value: 20282.64, duration: 0:00:02.033268\n",
       "episode: 57/200, episode end value: 23603.04, duration: 0:00:02.052970\n",
       "episode: 58/200, episode end value: 17321.54, duration: 0:00:02.001127\n",
       "episode: 59/200, episode end value: 18692.38, duration: 0:00:02.025994\n",
       "episode: 60/200, episode end value: 19903.23, duration: 0:00:02.017137\n",
       "episode: 61/200, episode end value: 18020.76, duration: 0:00:02.009129\n",
       "episode: 62/200, episode end value: 23815.36, duration: 0:00:02.082804\n",
       "episode: 63/200, episode end value: 20779.78, duration: 0:00:01.987234\n",
       "episode: 64/200, episode end value: 21226.38, duration: 0:00:01.999391\n",
       "episode: 65/200, episode end value: 20895.43, duration: 0:00:02.016266\n",
       "episode: 66/200, episode end value: 21155.07, duration: 0:00:02.032785\n",
       "episode: 67/200, episode end value: 21299.35, duration: 0:00:01.985297\n",
       "episode: 68/200, episode end value: 25754.29, duration: 0:00:01.992677\n",
       "episode: 69/200, episode end value: 19405.50, duration: 0:00:02.007831\n",
       "episode: 70/200, episode end value: 22183.52, duration: 0:00:02.040302\n",
       "episode: 71/200, episode end value: 21364.77, duration: 0:00:02.062721\n",
       "episode: 72/200, episode end value: 25034.69, duration: 0:00:02.022959\n",
       "episode: 73/200, episode end value: 24436.51, duration: 0:00:02.020118\n",
       "episode: 74/200, episode end value: 24105.15, duration: 0:00:02.157141\n",
       "episode: 75/200, episode end value: 24615.44, duration: 0:00:02.035381\n",
       "episode: 76/200, episode end value: 23565.01, duration: 0:00:02.078972\n",
       "episode: 77/200, episode end value: 21077.91, duration: 0:00:02.206295\n",
       "episode: 78/200, episode end value: 21744.66, duration: 0:00:02.049835\n",
       "episode: 79/200, episode end value: 21861.96, duration: 0:00:02.035586\n",
       "episode: 80/200, episode end value: 22191.07, duration: 0:00:02.040677\n",
       "episode: 81/200, episode end value: 20627.11, duration: 0:00:02.055863\n",
       "episode: 82/200, episode end value: 22264.21, duration: 0:00:02.081674\n",
       "episode: 83/200, episode end value: 24668.37, duration: 0:00:02.004131\n",
       "episode: 84/200, episode end value: 22985.68, duration: 0:00:02.351422\n",
       "episode: 85/200, episode end value: 21638.15, duration: 0:00:02.036847\n",
       "episode: 86/200, episode end value: 20068.76, duration: 0:00:02.005443\n",
       "episode: 87/200, episode end value: 21593.76, duration: 0:00:02.010317\n",
       "episode: 88/200, episode end value: 23489.62, duration: 0:00:02.053616\n",
       "episode: 89/200, episode end value: 22472.37, duration: 0:00:01.988477\n",
       "episode: 90/200, episode end value: 23173.01, duration: 0:00:02.065381\n",
       "episode: 91/200, episode end value: 22457.42, duration: 0:00:02.081652\n",
       "episode: 92/200, episode end value: 21656.99, duration: 0:00:02.007978\n",
       "episode: 93/200, episode end value: 22127.48, duration: 0:00:02.019278\n",
       "episode: 94/200, episode end value: 22633.08, duration: 0:00:01.996033\n",
       "episode: 95/200, episode end value: 22384.38, duration: 0:00:02.088946\n",
       "episode: 96/200, episode end value: 22203.82, duration: 0:00:02.024652\n",
       "episode: 97/200, episode end value: 22446.24, duration: 0:00:02.022557\n",
       "episode: 98/200, episode end value: 22127.48, duration: 0:00:02.010247\n",
       "episode: 99/200, episode end value: 19966.42, duration: 0:00:02.017017\n",
       "episode: 100/200, episode end value: 24412.55, duration: 0:00:02.036257\n",
       "episode: 101/200, episode end value: 22351.75, duration: 0:00:02.030530\n",
       "episode: 102/200, episode end value: 24970.90, duration: 0:00:02.023095\n",
       "episode: 103/200, episode end value: 25082.76, duration: 0:00:02.062394\n",
       "episode: 104/200, episode end value: 20388.94, duration: 0:00:02.038896\n",
       "episode: 105/200, episode end value: 25884.43, duration: 0:00:02.454684\n",
       "episode: 106/200, episode end value: 22386.02, duration: 0:00:02.109252\n",
       "episode: 107/200, episode end value: 22477.49, duration: 0:00:02.022254\n",
       "episode: 108/200, episode end value: 22425.44, duration: 0:00:02.047122\n",
       "episode: 109/200, episode end value: 22552.32, duration: 0:00:02.055068\n",
       "episode: 110/200, episode end value: 21852.41, duration: 0:00:02.017063\n",
       "episode: 111/200, episode end value: 25046.53, duration: 0:00:02.012060\n",
       "episode: 112/200, episode end value: 22430.34, duration: 0:00:02.044408\n",
       "episode: 113/200, episode end value: 22551.47, duration: 0:00:02.020882\n",
       "episode: 114/200, episode end value: 25002.83, duration: 0:00:02.061653\n",
       "episode: 115/200, episode end value: 21876.89, duration: 0:00:02.017463\n",
       "episode: 116/200, episode end value: 24345.23, duration: 0:00:02.255772\n",
       "episode: 117/200, episode end value: 23053.30, duration: 0:00:02.040689\n",
       "episode: 118/200, episode end value: 21434.12, duration: 0:00:02.012364\n",
       "episode: 119/200, episode end value: 21247.61, duration: 0:00:02.066744\n",
       "episode: 120/200, episode end value: 24003.55, duration: 0:00:02.010709\n",
       "episode: 121/200, episode end value: 22453.94, duration: 0:00:01.991314\n",
       "episode: 122/200, episode end value: 20822.56, duration: 0:00:02.117530\n",
       "episode: 123/200, episode end value: 22278.76, duration: 0:00:02.000985\n",
       "episode: 124/200, episode end value: 20070.16, duration: 0:00:02.074240\n",
       "episode: 125/200, episode end value: 19093.43, duration: 0:00:02.000111\n",
       "episode: 126/200, episode end value: 19567.07, duration: 0:00:02.017517\n",
       "episode: 127/200, episode end value: 20986.94, duration: 0:00:01.995603\n",
       "episode: 128/200, episode end value: 21713.98, duration: 0:00:02.047062\n",
       "episode: 129/200, episode end value: 17652.88, duration: 0:00:01.995154\n",
       "episode: 130/200, episode end value: 21365.84, duration: 0:00:02.373943\n",
       "episode: 131/200, episode end value: 21868.74, duration: 0:00:01.996434\n",
       "episode: 132/200, episode end value: 20604.37, duration: 0:00:02.039089\n",
       "episode: 133/200, episode end value: 21725.32, duration: 0:00:02.001831\n",
       "episode: 134/200, episode end value: 21724.49, duration: 0:00:02.031895\n",
       "episode: 135/200, episode end value: 19953.10, duration: 0:00:02.069308\n",
       "episode: 136/200, episode end value: 21767.27, duration: 0:00:02.004311\n",
       "episode: 137/200, episode end value: 20144.58, duration: 0:00:02.029739\n",
       "episode: 138/200, episode end value: 21286.91, duration: 0:00:02.011307\n",
       "episode: 139/200, episode end value: 21064.26, duration: 0:00:02.008325\n",
       "episode: 140/200, episode end value: 19156.34, duration: 0:00:02.033843\n",
       "episode: 141/200, episode end value: 20675.90, duration: 0:00:02.075970\n",
       "episode: 142/200, episode end value: 22636.65, duration: 0:00:02.038343\n",
       "episode: 143/200, episode end value: 22138.52, duration: 0:00:02.014306\n",
       "episode: 144/200, episode end value: 20918.96, duration: 0:00:02.027094\n",
       "episode: 145/200, episode end value: 21339.01, duration: 0:00:01.999797\n",
       "episode: 146/200, episode end value: 22015.10, duration: 0:00:02.037290\n",
       "episode: 147/200, episode end value: 21235.87, duration: 0:00:02.013569\n",
       "episode: 148/200, episode end value: 20675.90, duration: 0:00:02.033151\n",
       "episode: 149/200, episode end value: 20929.98, duration: 0:00:02.030717\n",
       "episode: 150/200, episode end value: 22113.57, duration: 0:00:02.044969\n",
       "episode: 151/200, episode end value: 22203.10, duration: 0:00:02.001418\n",
       "episode: 152/200, episode end value: 22960.67, duration: 0:00:01.996945\n",
       "episode: 153/200, episode end value: 21434.58, duration: 0:00:02.093184\n",
       "episode: 154/200, episode end value: 20792.66, duration: 0:00:02.025134\n",
       "episode: 155/200, episode end value: 21477.57, duration: 0:00:02.002419\n",
       "episode: 156/200, episode end value: 22598.13, duration: 0:00:02.012957\n",
       "episode: 157/200, episode end value: 21797.13, duration: 0:00:02.354425\n",
       "episode: 158/200, episode end value: 20851.69, duration: 0:00:02.429675\n",
       "episode: 159/200, episode end value: 21609.83, duration: 0:00:02.076091\n",
       "episode: 160/200, episode end value: 21887.73, duration: 0:00:02.021874\n",
       "episode: 161/200, episode end value: 22129.66, duration: 0:00:02.038049\n",
       "episode: 162/200, episode end value: 20878.07, duration: 0:00:02.024030\n",
       "episode: 163/200, episode end value: 21654.19, duration: 0:00:02.037422\n",
       "episode: 164/200, episode end value: 21281.42, duration: 0:00:02.079681\n",
       "episode: 165/200, episode end value: 22168.42, duration: 0:00:02.038355\n",
       "episode: 166/200, episode end value: 22807.66, duration: 0:00:02.030811\n",
       "episode: 167/200, episode end value: 21568.44, duration: 0:00:02.262496\n",
       "episode: 168/200, episode end value: 21334.05, duration: 0:00:02.030190\n",
       "episode: 169/200, episode end value: 21325.88, duration: 0:00:02.068162\n",
       "episode: 170/200, episode end value: 20909.04, duration: 0:00:01.990371\n",
       "episode: 171/200, episode end value: 22058.01, duration: 0:00:02.003556\n",
       "episode: 172/200, episode end value: 20223.51, duration: 0:00:02.006364\n",
       "episode: 173/200, episode end value: 21380.27, duration: 0:00:02.018875\n",
       "episode: 174/200, episode end value: 21982.29, duration: 0:00:01.993743\n",
       "episode: 175/200, episode end value: 21288.78, duration: 0:00:01.990389\n",
       "episode: 176/200, episode end value: 21220.99, duration: 0:00:02.019202\n",
       "episode: 177/200, episode end value: 21628.27, duration: 0:00:02.015179\n",
       "episode: 178/200, episode end value: 21880.07, duration: 0:00:02.055620\n",
       "episode: 179/200, episode end value: 21529.26, duration: 0:00:02.028042\n",
       "episode: 180/200, episode end value: 21507.61, duration: 0:00:01.981320\n",
       "episode: 181/200, episode end value: 20906.08, duration: 0:00:02.008319\n",
       "episode: 182/200, episode end value: 21546.60, duration: 0:00:02.010673\n",
       "episode: 183/200, episode end value: 22115.46, duration: 0:00:02.049971\n",
       "episode: 184/200, episode end value: 22054.90, duration: 0:00:02.017395\n",
       "episode: 185/200, episode end value: 21749.78, duration: 0:00:01.990395\n",
       "episode: 186/200, episode end value: 22013.11, duration: 0:00:02.044922\n",
       "episode: 187/200, episode end value: 22047.88, duration: 0:00:02.045694\n",
       "episode: 188/200, episode end value: 21041.03, duration: 0:00:02.037018\n",
       "episode: 189/200, episode end value: 22879.24, duration: 0:00:02.028041\n",
       "episode: 190/200, episode end value: 20503.33, duration: 0:00:02.032295\n",
       "episode: 191/200, episode end value: 21453.86, duration: 0:00:02.149383\n",
       "episode: 192/200, episode end value: 21399.07, duration: 0:00:02.054907\n",
       "episode: 193/200, episode end value: 21288.78, duration: 0:00:02.038913\n",
       "episode: 194/200, episode end value: 21338.04, duration: 0:00:02.073986\n",
       "episode: 195/200, episode end value: 21459.36, duration: 0:00:02.019388\n",
       "episode: 196/200, episode end value: 19563.06, duration: 0:00:01.993404\n",
       "episode: 197/200, episode end value: 21026.27, duration: 0:00:02.018104\n",
       "episode: 198/200, episode end value: 21480.48, duration: 0:00:02.038474\n",
       "episode: 199/200, episode end value: 21445.97, duration: 0:00:01.999085\n",
       "episode: 200/200, episode end value: 21041.62, duration: 0:00:02.012265\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# play the game num_episodes times\n",
    "for e in range(num_episodes):\n",
    "  t0 = datetime.now()\n",
    "  val = play_one_episode(agent, env, mode)\n",
    "  dt = datetime.now() - t0\n",
    "  print(f\"episode: {e + 1}/{num_episodes}, episode end value: {val:.2f}, duration: {dt}\")\n",
    "  portfolio_value.append(val) # append episode end portfolio value\n",
    "\n",
    "# save the weights when we are done\n",
    "if mode == 'train':\n",
    "  # save the DQN\n",
    "  agent.save(f'{models_folder}/dqn.h5')\n",
    "\n",
    "  # save the scaler\n",
    "  with open(f'{models_folder}/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "\n",
    "# save portfolio value for each episode\n",
    "np.save(f'{rewards_folder}/{mode}.npy', portfolio_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mode = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_pred = []\n",
    "if mode == 'test':\n",
    "  # then load the previous scaler\n",
    "  with open(f'{models_folder}/scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "  # remake the env with test data\n",
    "  env = MultiStockEnv(test_data, initial_investment)\n",
    "\n",
    "  # make sure epsilon is not 1!\n",
    "  # no need to run multiple episodes if epsilon = 0, it's deterministic\n",
    "  agent.epsilon = 0.01\n",
    "\n",
    "  # load trained weights\n",
    "  agent.load(f'{models_folder}/dqn.h5')\n",
    "\n",
    "# play the game num_episodes times\n",
    "for e in range(num_episodes):\n",
    "  t0 = datetime.now()\n",
    "  val = play_one_episode(agent, env, mode)\n",
    "  dt = datetime.now() - t0\n",
    "  print(f\"episode: {e + 1}/{num_episodes}, episode end value: {val:.2f}, duration: {dt}\")\n",
    "  portfolio_pred.append(val) # append episode end portfolio value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(portfolio_value, label='train')\n",
    "plt.plot(portfolio_pred, label='test')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "name": "rl_trader_A2C",
  "notebookId": 1660354639089231,
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
